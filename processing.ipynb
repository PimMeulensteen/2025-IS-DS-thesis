{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import xml.etree.ElementTree as ET\n",
    "from result_helpers import * \n",
    "\n",
    "from ledger import Ledger\n",
    "from compare_csv import compare\n",
    "from colours import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"input_jpg_xml\"\n",
    "\n",
    "ledgers = []\n",
    "for root, dirs, files in os.walk(folder):\n",
    "    for file in files:\n",
    "        if file.endswith(\".jpg\") and file.startswith(\"WBM\"):\n",
    "            l = Ledger(os.path.join(root, file), str(file.strip(\".jpg\")))\n",
    "            ledgers.append(l)\n",
    "\n",
    "print(len(ledgers), \"images found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split double pages into two\n",
    "double_pages = [l for l in ledgers if l.is_double_page()]\n",
    "print(len(double_pages), \"double pages found\")\n",
    "for ledger in tqdm(double_pages):\n",
    "    left, right = ledger.split_into_two()\n",
    "    ledgers.remove(ledger)\n",
    "    ledgers.append(left)\n",
    "    ledgers.append(right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "new_ledgers = []\n",
    "for led in tqdm(ledgers):\n",
    "    # Get image and make the image grayscale\n",
    "    im = led.cropped_im.copy()\n",
    "    im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Take the average colour of each row in the led.contrast_im between 10% and 90% of the width   \n",
    "    row_colours = []\n",
    "    for row in range(im.shape[0]):\n",
    "        row_colours.append(np.mean(im[row, int(im.shape[1]*0.1):int(im.shape[1]*0.9)], axis=0))\n",
    "\n",
    "    row_colours = np.array(row_colours)\n",
    "    STEP_SIZE = 400\n",
    "    i = STEP_SIZE\n",
    "    regions = []\n",
    "    while i < len(row_colours):\n",
    "        # Calculte the sum of the differences between each row colour and the previous row colour\n",
    "        diff = 0\n",
    "        for j in range(STEP_SIZE):\n",
    "            diff += np.sum(np.abs(row_colours[i-j] - row_colours[i-j-1]))\n",
    "            if diff > STEP_SIZE/15:\n",
    "                break\n",
    "\n",
    "        # If the difference is greater than 1000, draw a line\n",
    "        if diff < STEP_SIZE/15: \n",
    "            regions.append((i-STEP_SIZE, i))\n",
    "            # Draw a area from start to end\n",
    "            start = i - STEP_SIZE\n",
    "            end = i-1\n",
    "            i += STEP_SIZE\n",
    "        i += 1\n",
    "\n",
    "    i = 0\n",
    "    while i < len(regions):\n",
    "        if regions[i][1] + 2* STEP_SIZE > len(row_colours):\n",
    "            regions[i] = (regions[i][0], len(row_colours))\n",
    "        if i + 1 < len(regions) and regions[i+1][0] - regions[i][1] < 10:\n",
    "            regions[i] = (regions[i][0], regions[i+1][1])\n",
    "            regions.pop(i+1)\n",
    "        else:\n",
    "            i += 1\n",
    "            \n",
    "    splits = []\n",
    "    for region in regions:\n",
    "        if region[1] < len(row_colours):\n",
    "            splits.append((region[0] + region[1])//2)\n",
    "\n",
    "    if not splits:\n",
    "        new_ledgers.append(led)\n",
    "\n",
    "    for i, split in enumerate(splits[::-1]):\n",
    "        # If it's the last split\n",
    "        if i + 1 == len(splits):\n",
    "            top, bottom = led.horizontal_split(split, f\"-{len(splits)-1-i}\", f\"-{len(splits)-i}\")\n",
    "            new_ledgers.append(top)\n",
    "            new_ledgers.append(bottom)\n",
    "        else:\n",
    "            top, bottom = led.horizontal_split(split, \"\", f\"-{len(splits)-i}\")\n",
    "            led = top\n",
    "            new_ledgers.append(bottom)\n",
    "\n",
    "print(len(new_ledgers), \"images found. Was \", len(ledgers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ledgers = new_ledgers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn each ledger into two by spliting it along the middle line\n",
    "new_ledgers = []\n",
    "for led in (ledgers):\n",
    "    # led.remove_borders()\n",
    "    led.find_vertical_lines()\n",
    "\n",
    "    if len(led.vert_lines) < 10:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        led.find_middle_line()\n",
    "    except:\n",
    "        print(\"Cannot find middle line for\", led.id)\n",
    "        cv2.imwrite(f\"not_split/{led.id}.jpg\", led.cropped_im)\n",
    "        continue\n",
    "\n",
    "    ml = led.middle_line\n",
    "    ml_i = led.middle_line_index\n",
    "    left_lines = led.vert_lines[:ml_i]\n",
    "    right_lines = led.vert_lines[ml_i:]\n",
    "\n",
    "\n",
    "    end_left = max(ml[0], ml[1])\n",
    "    start_right = min(ml[0], ml[1])\n",
    "\n",
    "    left = led.cropped_im[:, :end_left]\n",
    "    right = led.cropped_im[:, start_right:]\n",
    "    \n",
    "    print(\"left\", left.shape, \"right\", right.shape, ml_i, len(led.vert_lines), led.id)\n",
    "\n",
    "    left_led = Ledger.from_image(left, ledger_id=f\"{led.id}-l\")\n",
    "    left_led.cropped_left = led.cropped_left\n",
    "    left_led.cropped_top = led.cropped_top\n",
    "    left_led._vert_lines = left_lines\n",
    "    new_ledgers.append(left_led)\n",
    "\n",
    "    right_led = Ledger.from_image(right, ledger_id=f\"{led.id}-r\")\n",
    "    right_led.cropped_left = start_right + led.cropped_left\n",
    "    right_led.cropped_top = led.cropped_top\n",
    "    right_led._vert_lines = right_lines\n",
    "    new_ledgers.append(right_led)\n",
    "\n",
    "    im = np.copy(led.cropped_im)\n",
    "    for line in right_lines:\n",
    "        cv2.line(im, (line.top, 0), (line.bottom, im.shape[0]), (0, 0, 255), 10)\n",
    "    for line in left_lines:\n",
    "        cv2.line(im, (line.top, 0), (line.bottom, im.shape[0]), (0, 255, 0), 10)\n",
    "    cv2.imwrite(f\"2/{led.id}.jpg\", im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ledgers = new_ledgers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precalc_ledger(ledger):\n",
    "    ledger.contrast_im\n",
    "    ledger.find_vertical_lines()\n",
    "    ledger.check_vertical_lines()\n",
    "\n",
    "    im = ledger.cropped_im.copy()\n",
    "    for top, bottom in ledger.vert_lines:\n",
    "        cv2.line(im, (top, 0), (bottom, im.shape[0]), RED, 5)\n",
    "\n",
    "    cv2.imwrite(f\"_tmp_loghi/{ledger.id}.jpg\", im)\n",
    "    return ledger\n",
    "\n",
    "\n",
    "for led in tqdm(ledgers):\n",
    "    try:\n",
    "        led = precalc_ledger(led)\n",
    "    except Exception as e:\n",
    "        print(\"Error in\", led.id)\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_found = [\"WBMB00038000380-r\", \"WBMB00048000470-r\", \"WBMB00048000440-r\", \" WBMB00018000040-r\", \"WBMB00028000370-r\"]\n",
    "# for led in ledgers:\n",
    "    # if led.id in not_found:\n",
    "        # ledger.del(led)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure loghi has run by checking if '_tmp_loghi/page' has a xml file for\n",
    "# each image in '_tmp_loghi'\n",
    "all_imgs = os.listdir(\"_tmp_loghi\")\n",
    "all_imgs = [i for i in all_imgs if i.endswith(\".jpeg\")]\n",
    "\n",
    "all_xmls = os.listdir(\"_tmp_loghi/page\")\n",
    "all_xmls = [i[:-3] for i in all_xmls if i.endswith(\".xml\")]\n",
    "\n",
    "\n",
    "\n",
    "assert [i[:-3] in all_xmls for i in all_imgs], \"Loghi has not run on all images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_offset(led, line):\n",
    "    vl = led.vert_lines\n",
    "    return vl[line][0]\n",
    "\n",
    "# Define color mapping for bins\n",
    "color_map = {\n",
    "    0: RED, 1: BLUE, 2: GREEN, 3: ORANGE, \n",
    "    4: CYAN, 5: MAGENTA, 6: WHITE, 7: BLACK, \n",
    "    8: GREY, 9: ORANGE\n",
    "}\n",
    "\n",
    "all_results = []\n",
    "\n",
    "# Process each ledger\n",
    "for ledger in tqdm(ledgers):\n",
    "    try:\n",
    "        # Load the corresponding image and XML file\n",
    "        image_path = f\"_tmp_loghi/{ledger.id}.jpg\"\n",
    "        xml_path = f\"_tmp_loghi/page/{ledger.id}.xml\"\n",
    "        cur_image = cv2.imread(image_path)\n",
    "        tree = ET.parse(xml_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Missing file(s) for ledger ID {ledger.id}\")\n",
    "        continue\n",
    "\n",
    "    root = tree.getroot()\n",
    "    namespace = get_ns(root)\n",
    "\n",
    "   \n",
    "    \n",
    "    # Define bin borders based on vertical lines\n",
    "    bin_borders = [0] + [line.top for line in ledger.vert_lines] + [ledger.cropped_im.shape[1]]\n",
    "    if not 6 <= len(bin_borders) <= 8:\n",
    "        print(f\"Error: Invalid number of bins ({len(bin_borders)}) for ledger ID {ledger.id}\")\n",
    "\n",
    "        for t, b in ledger.vert_lines:\n",
    "            cv2.line(cur_image, (t, 0), (b, cur_image.shape[0]), (0, 0, 255), 5)\n",
    "\n",
    "        cv2.imwrite(f\"no_bins/{ledger.id}.jpeg\", cur_image)\n",
    "        continue\n",
    "\n",
    "\n",
    "    # Initialize bins for text lines\n",
    "    bins = [[] for _ in range(10)]\n",
    "\n",
    "    # Classify text lines into bins\n",
    "    for text_line_element in root.findall(f\".//{namespace}TextLine\"):\n",
    "        text_line = LineOfText(text_line_element, namespace)\n",
    "        \n",
    "        weird_char = [',', '!', '?', '(', ')', '[', ']', '{', '}', '<', '>', '|', \n",
    "                      '\\\\', '/', '*', '+', '=', '&', '%', '$', '#', '@', '^', '~', \n",
    "                      '`', '\"', \"'\", ':', ';', ' ', '-', '_', '.']\n",
    "        if all(i in weird_char for i in text_line.plain_text):\n",
    "            continue\n",
    "\n",
    "        # Check in which bin the baseline is.\n",
    "        bin_num = next(i for i, border in enumerate(bin_borders) if text_line.avg_x < border)-1\n",
    "\n",
    "\n",
    "        # Determine the bin for the current text line\n",
    "        try:\n",
    "            bin_index = next(\n",
    "                i for i, border in enumerate(bin_borders) if text_line.avg_x < border\n",
    "            ) - 1\n",
    "        except StopIteration:\n",
    "            continue\n",
    "\n",
    "        # Skip short text in bin 1\n",
    "        if bin_index == 1 and len(text_line.plain_text.strip()) < 2:\n",
    "            continue\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        bins[bin_index].append(text_line)\n",
    "\n",
    "        \n",
    "        SHRINK_PX = 40 if bin_index == 1 else 20\n",
    "        # Draw baseline for lines in their respective bins as a rectangle\n",
    "        cv2.rectangle(\n",
    "            cur_image, \n",
    "            (text_line.reg_min_x + SHRINK_PX, text_line.reg_min_y + SHRINK_PX), \n",
    "            (text_line.reg_max_x- SHRINK_PX, text_line.reg_max_y-SHRINK_PX), \n",
    "            color_map[bin_index], 2\n",
    "        )\n",
    "\n",
    "        # cv2.polylines(cur_image, [np.array(text_line.points)], False, color_map[bin_index], 2)\n",
    "\n",
    "    # Process subtotal lines (bin 3 expected to have numbers)\n",
    "    subtotal_items = []\n",
    "    ledger.find_subtotal_lines(0.725)\n",
    "    for left_line, right_line, row1, row2 in ledger.subtotal_lines:\n",
    "        closest_line = None\n",
    "        min_distance = float('inf')\n",
    "        subtotal_y_value = min(row1, row2)\n",
    "        has_value_above = False\n",
    "\n",
    "        # Find the closest line below the subtotal line in bin 3\n",
    "        for text_line in bins[3]:\n",
    "            if text_line.avg_y < subtotal_y_value + 25:\n",
    "                has_value_above = True\n",
    "                continue\n",
    "\n",
    "            distance = abs(text_line.avg_y - subtotal_y_value)\n",
    "            if distance < min_distance:\n",
    "                min_distance = distance\n",
    "                closest_line = text_line\n",
    "\n",
    "        # Draw the subtotal line\n",
    "        cv2.line(cur_image, (left_line[0], row2), (right_line[0], row1), BLUE, 5)\n",
    "\n",
    "        # Highlight the value below the subtotal line\n",
    "        if closest_line and min_distance < 175 and has_value_above:\n",
    "            # cv2.polylines(cur_image, [np.array(closest_line.points)], False, (0,255,0), 10)\n",
    "            cv2.rectangle(\n",
    "                cur_image, \n",
    "                (closest_line.reg_min_x + SHRINK_PX, closest_line.reg_min_y + SHRINK_PX), \n",
    "                (closest_line.reg_max_x- SHRINK_PX, closest_line.reg_max_y-SHRINK_PX), \n",
    "                BLUE, 5\n",
    "            )\n",
    "            subtotal_items.append((closest_line, text_line))\n",
    "            bins[3].remove(closest_line)\n",
    "\n",
    "    # Merge close text lines in bin 1\n",
    "    bins[1].sort(key=lambda x: x.avg_y)\n",
    "    merged_bin_1 = []\n",
    "    DIST_THRESHOLD = 600\n",
    "\n",
    "    for idx, text_line in enumerate(bins[1]):\n",
    "\n",
    "        if idx == 0:\n",
    "            merged_bin_1.append(text_line)\n",
    "            continue\n",
    "\n",
    "        prev_line = merged_bin_1[-1]\n",
    "        last_point_prev = prev_line.points[-1]\n",
    "        first_point = text_line.points[0]\n",
    "\n",
    "        # Compute distance between lines\n",
    "        dist = np.linalg.norm(np.array(last_point_prev) - np.array(first_point))\n",
    "        delta_y = abs(last_point_prev[1] - first_point[1])\n",
    "\n",
    "        if dist < DIST_THRESHOLD and delta_y < 35:\n",
    "            prev_line.plain_text += \" \" + text_line.plain_text\n",
    "            merged_bin_1[-1] = prev_line\n",
    "            cv2.line(cur_image, last_point_prev, first_point, (0, 155, 0), 2)\n",
    "        else:\n",
    "            merged_bin_1.append(text_line)\n",
    "\n",
    "    bins[1] = merged_bin_1\n",
    "\n",
    "    # Generate table rows and map lines from bins to rows\n",
    "    table_rows = [[\"\", line, \"\", \"\", \"\", \"\"] for line in bins[1] if len(line.plain_text) > 1]\n",
    "\n",
    "    for bin_index in [0, 2, 3, 4]:\n",
    "        for text_line in bins[bin_index]:\n",
    "            closest_row = min(\n",
    "                table_rows, key=lambda row: abs(row[1].avg_y - text_line.avg_y), default=None\n",
    "            )\n",
    "\n",
    "            if closest_row:\n",
    "                closest_row[bin_index] = text_line\n",
    "\n",
    "    # # Add empty rows with just the subtotal in the correct spots\n",
    "    for i, (cl, line) in enumerate(subtotal_items):\n",
    "        # Loop over the table rows and find the two rows where the subtotal should fit in between.\n",
    "        placed = False\n",
    "        for j, row in enumerate(table_rows):\n",
    "            if not row[1]:\n",
    "                continue\n",
    "\n",
    "            if row[1].avg_y > cl.avg_y:\n",
    "                table_rows.insert(j, [\"\", \"\", \"\", cl, \"\", \"\"])\n",
    "                placed = True\n",
    "                break\n",
    "\n",
    "        if not placed:\n",
    "            table_rows.append([\"\", \"\", \"\", cl, \"\", \"\"])\n",
    "\n",
    "    # Save table_rows as a Results object\n",
    "    results = []\n",
    "    for row in table_rows:\n",
    "        # Skip empty rows\n",
    "        if all(cell == \"\" or not cell or cell is None for cell in row):\n",
    "            print(\"Skipped an empty row\")\n",
    "            continue\n",
    "\n",
    "        # Create a copy of the row for modifications\n",
    "        row_copy = row.copy()\n",
    "        date_cell = row[0]\n",
    "\n",
    "        # Check and adjust date placement\n",
    "        if not date_cell and row[1]:\n",
    "            # If the second column starts with a number, treat it as a date and move it to the first column\n",
    "            words = row[1].plain_text.split()\n",
    "            numeric_words = [i for i in words if any(char.isnumeric() for char in i)]\n",
    "            \n",
    "            if numeric_words:\n",
    "                split_index = words.index(numeric_words[-1]) + 1\n",
    "                possible_date = \" \".join(words[:split_index])\n",
    "\n",
    "                # Update the date in the first column\n",
    "                row_copy[0] = LineOfText.from_string(possible_date)\n",
    "                # Remove the moved date from the second column\n",
    "                row_copy[1].plain_text = row_copy[1].plain_text[len(possible_date) + 1 :]\n",
    "\n",
    "        # Draw lines between cells in the same row\n",
    "        prev_cell = None\n",
    "        for i in range(0, len(row_copy)):\n",
    "            if type(row_copy[i]) == LineOfText and row_copy[i].line is not None:\n",
    "                if not prev_cell:\n",
    "                    prev_cell = row_copy[i]\n",
    "                    continue\n",
    "\n",
    "                cv2.line(\n",
    "                    cur_image, \n",
    "                    (prev_cell.max_x, prev_cell.avg_y), \n",
    "                    (row_copy[i].min_x, row_copy[i].avg_y), \n",
    "                    (0, 0, 0), 2\n",
    "                )\n",
    "                prev_cell = row_copy[i]\n",
    "\n",
    "\n",
    "        # Convert the row into a structured format\n",
    "        structured_row = [\n",
    "            Cell(\n",
    "                cell.plain_text,\n",
    "                [(x + led.cropped_left, y + led.cropped_top) for x, y in cell.region_points]\n",
    "            ) if cell else Cell(None)\n",
    "            for cell in row_copy\n",
    "        ]\n",
    "\n",
    "        # Add the structured row to the results\n",
    "        results.append(ResultsRow.from_row(structured_row))\n",
    "    cv2.imwrite(f\"out_img/{ledger.id}.jpeg\", cur_image)\n",
    "\n",
    "    # Append the results for the current ledger to the final collection\n",
    "    all_results.append(Results(results, ledger.id))\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in all_results:\n",
    "    # Save the results as a CSV file\n",
    "    a = r.to_csv()\n",
    "    print(a, file=open(f\"out_csv/{r.name}.csv\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from ledger import Ledger\n",
    "# Remove previusly saved results\n",
    "if os.path.exists(\"all_results.pkl\"):\n",
    "    os.remove(\"all_results.pkl\")\n",
    "\n",
    "with open(\"all_results.pkl\", \"wb\") as f:\n",
    "    pickle.dump(all_results, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
